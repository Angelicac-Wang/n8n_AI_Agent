{
  "name": "@n8n/n8n-nodes-langchain.lmChatAwsBedrock",
  "displayName": "AWS Bedrock Chat Model",
  "description": "Language Model AWS Bedrock",
  "properties": [
    {
      "displayName": "This node must be connected to an AI chain. <a data-action='openSelectiveNodeCreator' data-action-parameter-creatorview='AI'>Insert one</a>",
      "name": "notice",
      "type": "notice",
      "default": "",
      "typeOptions": {
        "containerClass": "ndv-connection-hint-notice"
      }
    },
    {
      "displayName": "Model Source",
      "name": "modelSource",
      "type": "options",
      "displayOptions": {
        "show": {
          "@version": [
            {
              "_cnd": {
                "gte": 1.1
              }
            }
          ]
        }
      },
      "options": [
        {
          "name": "On-Demand Models",
          "value": "onDemand",
          "description": "Standard foundation models with on-demand pricing"
        },
        {
          "name": "Inference Profiles",
          "value": "inferenceProfile",
          "description": "Cross-region inference profiles (required for models like Claude Sonnet 4 and others)"
        }
      ],
      "default": "onDemand",
      "description": "Choose between on-demand foundation models or inference profiles"
    },
    {
      "displayName": "Model",
      "name": "model",
      "type": "options",
      "allowArbitraryValues": true,
      "description": "The model which will generate the completion. <a href=\"https://docs.aws.amazon.com/bedrock/latest/userguide/foundation-models.html\">Learn more</a>.",
      "displayOptions": {
        "hide": {
          "modelSource": [
            "inferenceProfile"
          ]
        }
      },
      "typeOptions": {
        "loadOptionsDependsOn": [
          "modelSource"
        ],
        "loadOptions": {
          "routing": {
            "request": {
              "method": "GET",
              "url": "/foundation-models?&byOutputModality=TEXT&byInferenceType=ON_DEMAND"
            },
            "output": {
              "postReceive": [
                {
                  "type": "rootProperty",
                  "properties": {
                    "property": "modelSummaries"
                  }
                },
                {
                  "type": "setKeyValue",
                  "properties": {
                    "name": "={{$responseItem.modelName}}",
                    "description": "={{$responseItem.modelArn}}",
                    "value": "={{$responseItem.modelId}}"
                  }
                },
                {
                  "type": "sort",
                  "properties": {
                    "key": "name"
                  }
                }
              ]
            }
          }
        }
      },
      "routing": {
        "send": {
          "type": "body",
          "property": "model"
        }
      },
      "default": ""
    },
    {
      "displayName": "Model",
      "name": "model",
      "type": "options",
      "allowArbitraryValues": true,
      "description": "The inference profile which will generate the completion. <a href=\"https://docs.aws.amazon.com/bedrock/latest/userguide/inference-profiles-use.html\">Learn more</a>.",
      "displayOptions": {
        "show": {
          "modelSource": [
            "inferenceProfile"
          ]
        }
      },
      "typeOptions": {
        "loadOptionsDependsOn": [
          "modelSource"
        ],
        "loadOptions": {
          "routing": {
            "request": {
              "method": "GET",
              "url": "/inference-profiles?maxResults=1000"
            },
            "output": {
              "postReceive": [
                {
                  "type": "rootProperty",
                  "properties": {
                    "property": "inferenceProfileSummaries"
                  }
                },
                {
                  "type": "setKeyValue",
                  "properties": {
                    "name": "={{$responseItem.inferenceProfileName}}",
                    "description": "={{$responseItem.description || $responseItem.inferenceProfileArn}}",
                    "value": "={{$responseItem.inferenceProfileId}}"
                  }
                },
                {
                  "type": "sort",
                  "properties": {
                    "key": "name"
                  }
                }
              ]
            }
          }
        }
      },
      "routing": {
        "send": {
          "type": "body",
          "property": "model"
        }
      },
      "default": ""
    },
    {
      "displayName": "Options",
      "name": "options",
      "placeholder": "Add Option",
      "description": "Additional options to add",
      "type": "collection",
      "default": {},
      "options": [
        {
          "displayName": "Maximum Number of Tokens",
          "name": "maxTokensToSample",
          "default": 2000,
          "description": "The maximum number of tokens to generate in the completion",
          "type": "number"
        },
        {
          "displayName": "Sampling Temperature",
          "name": "temperature",
          "default": 0.7,
          "typeOptions": {
            "maxValue": 1,
            "minValue": 0,
            "numberPrecision": 1
          },
          "description": "Controls randomness: Lowering results in less random completions. As the temperature approaches zero, the model will become deterministic and repetitive.",
          "type": "number"
        }
      ]
    }
  ]
}